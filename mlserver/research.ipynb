{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': 'The video discusses the relationship between machine learning and physics, with a Nobel Prize in Physics awarded to machine learning. The speaker questions whether this is truly a physics prize, but ultimately concludes that it is fine to make exceptions for old institutions adapting to new fields.', 'key_points': ['Machine learning and neural networks are not traditional physics', 'The Nobel Prize in Physics was awarded to machine learning', 'Some argue that machine learning is more closely related to software engineering or electrical engineering than physics', 'Others see this as an exception rather than the norm'], 'topics': ['Machine Learning', 'Neural Networks', 'Nobel Prizes', 'Physics', 'Exceptional Cases'], 'key_moments': [{'timestamp': '00:10:00', 'description': 'The speaker introduces the topic of machine learning and its relationship to physics'}, {'timestamp': '00:20:00', 'description': \"The Nobel Prize in Physics is awarded to machine learning, sparking debate about whether it's truly a physics prize\"}, {'timestamp': '00:30:00', 'description': 'Some argue that machine learning is more closely related to software engineering or electrical engineering than physics'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "# from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "from pathlib import Path\n",
    "import ollama\n",
    "\n",
    "# model = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "transcript = \"\"\"\n",
    "[0.00 - 10.00]: In this video, I will explain the very basics of artificial neural networks for people who have no idea what they are and how they work.\n",
    "[10.00 - 12.00]: Like at all.\n",
    "[12.00 - 25.00]: The 2024 Nobel Prize in Physics was awarded to John Hopfield and Jeffrey Hinton for their contributions to artificial neural networks, enabling machine learning and the recent breakthroughs in AI.\n",
    "[25.00 - 27.00]: Wait what?\n",
    "[28.00 - 35.00]: Well, not gonna lie. Like most observers, I was very surprised by this choice.\n",
    "[35.00 - 41.00]: Not because I feel it's undisurbing, but because it's categorized as physics.\n",
    "[42.00 - 43.00]: I don't know.\n",
    "[43.00 - 46.00]: I'm the one who is the king of music, I'm the one who is the king of physics.\n",
    "[46.00 - 47.00]: Physics!\n",
    "[47.00 - 48.00]: Motherf**k!\n",
    "[71.00 - 75.00]: What I'm going to do here is go into a lot of details or even math.\n",
    "[75.00 - 83.00]: Because this is more of a, I don't know anything about machine learning, please explain to me in SpongeBob term situation.\n",
    "[83.00 - 85.00]: First, neural networks.\n",
    "[85.00 - 90.00]: Neural networks are based on how biological neurons or nerve cells work in our brain.\n",
    "[90.00 - 97.00]: These cells take in several input signals, process them, and generate an output signal or signals.\n",
    "[97.00 - 102.00]: Our brain is made up of a complex network of those neurons.\n",
    "[102.00 - 108.00]: And artificial neural networks are just computer programs modeled on this very structure.\n",
    "[108.00 - 112.00]: To be clear, they are not hardware. They do not exist materially.\n",
    "[112.00 - 117.00]: They are just a diagram describing the structure of a computation.\n",
    "[117.00 - 123.00]: I can draw an artificial neural network on a piece of paper and do all the calculations by hand.\n",
    "[123.00 - 127.00]: That is the exact same thing that happens inside the computer.\n",
    "[127.00 - 129.00]: Or slower of course.\n",
    "[129.00 - 131.00]: And with more errors.\n",
    "[131.00 - 133.00]: But that's the first thing.\n",
    "[133.00 - 139.00]: Artificial neural networks are just computer programs, or rather a structure describing a program.\n",
    "[139.00 - 145.00]: They can be visualized by a graph containing edges that carry inputs and or outputs,\n",
    "[145.00 - 148.00]: and notes where the computations are performed.\n",
    "[148.00 - 153.00]: Typically, notes receive many inputs from all connected nodes.\n",
    "[153.00 - 160.00]: Computing output and send this to all connected nodes again, like a biological neuron.\n",
    "[160.00 - 167.00]: A simple example would be that at a node, all incoming inputs are just added up.\n",
    "[167.00 - 176.00]: Additionally, edges are weighted, meaning they will influence the computation at a node more or less depending on their weight.\n",
    "[176.00 - 183.00]: For example, all inputs at a node might at first be multiplied by their weight and then added up.\n",
    "[183.00 - 187.00]: Notice that all the computations performed here are very basic.\n",
    "[187.00 - 190.00]: It's just addition and multiplication.\n",
    "[190.00 - 195.00]: And even with just a small number of nodes, you can have a gigantic number of edges.\n",
    "[195.00 - 201.00]: And this is where the great complexity and also the power of neural networks come from.\n",
    "[201.00 - 209.00]: Depending on a network, the number of edges can scale exponentially or even super exponentially with the number of nodes.\n",
    "[209.00 - 214.00]: You can even see that by the interesting optical patterns that such networks create.\n",
    "[214.00 - 219.00]: You can literally tell the complexity just by looking at them.\n",
    "[219.00 - 225.00]: But basically, a neural network is just a very complex, convoluted function.\n",
    "[225.00 - 232.00]: You put some numbers in at one end, some computations are performed and then you get some numbers out.\n",
    "[243.00 - 253.00]: A hotfield network consists of nodes that can only be in one of two states and are connected to all other nodes by weighted edges that go in both directions symmetrically.\n",
    "[253.00 - 257.00]: In each computational step, just a single node is chosen.\n",
    "[257.00 - 264.00]: It takes all inputs from connected nodes together with the weights attached and computes whether it should be flipped or not.\n",
    "[264.00 - 267.00]: Then another node is chosen, et cetera, et cetera.\n",
    "[267.00 - 280.00]: A hotfield network can be used to first store patterns and then when it is given another pattern as input, it can retrace to which stored pattern this is the most similar to.\n",
    "[280.00 - 285.00]: So basically, autocorrect and autocomplete for patterns.\n",
    "[285.00 - 295.00]: So for example, you could encode the pixels of an image as a pattern and then reconstruct this original pattern from inputs that are similar.\n",
    "[295.00 - 300.00]: The way this is done is based on an idea from physics, minimizing energy.\n",
    "[300.00 - 305.00]: You will have noticed that with gravity, things don't move around randomly.\n",
    "[305.00 - 310.00]: On their own, balls don't ever roll uphill, just down here.\n",
    "[310.00 - 312.00]: How does a ball know where to roll?\n",
    "[312.00 - 315.00]: It does not have to try out all possible paths.\n",
    "[315.00 - 320.00]: Gravity will always make it roll the path most directly down here.\n",
    "[320.00 - 323.00]: This way, energy is minimized.\n",
    "[323.00 - 326.00]: The same principle is applied to the hotfield network.\n",
    "[326.00 - 335.00]: The stored patterns are set as states of lowest energy, local minima, which is achieved by fixing the weights of all edges.\n",
    "[335.00 - 345.00]: Then, during each step of computation, the energy of the network pattern is evaluated and is changed such that the energies are always minimized.\n",
    "[345.00 - 349.00]: This will iterate the pattern to the closest local minimum.\n",
    "[349.00 - 351.00]: So the closest stored pattern.\n",
    "[351.00 - 362.00]: Note that this is a very basic network with a lot of limitations, but it was one of the first demonstrations of what could be achieved with neural networks.\n",
    "[374.00 - 379.00]: Let's look at a more capable neural network, classical machine learning.\n",
    "[380.00 - 391.00]: For example, let's imagine we have a neural network where you enter an image of an animal as input and it tries to figure out whether this is an image of a cat or dog.\n",
    "[391.00 - 394.00]: You start with a network like this.\n",
    "[394.00 - 402.00]: Note that there is no clear rule how large a network like this has to be, how many nodes and how many layers it needs, etc.\n",
    "[402.00 - 406.00]: All of those things come down to trial and error or experience.\n",
    "[407.00 - 412.00]: Also, the initial weights can be either random or based on experience as well.\n",
    "[412.00 - 416.00]: You have a number of nodes that take input from outside the program.\n",
    "[416.00 - 419.00]: In this case, the brightness of pixels of an image.\n",
    "[419.00 - 423.00]: So, at each input node, you now have a number.\n",
    "[423.00 - 431.00]: These numbers are then sent to the next layer of nodes, which are called hidden nodes, because they are calculating just an intermediate step of the program.\n",
    "[432.00 - 442.00]: Again, each node gets a lot of numbers as input and each number will be multiplied by its weight and all of this will then be summed up to get a new number.\n",
    "[442.00 - 451.00]: Okay, so the numbers of the input layer were the brightness of pixels, but what are the numbers calculated by the hidden layers?\n",
    "[451.00 - 457.00]: And that's kind of the thing, and that's why we often talk about AI being a black box.\n",
    "[457.00 - 464.00]: Because these numbers are just representations for some characteristic or pattern within the input.\n",
    "[464.00 - 470.00]: It's nothing a human could do anything with. In fact, to us, it looks like random noise.\n",
    "[470.00 - 473.00]: We as humans would use completely different criteria.\n",
    "[473.00 - 478.00]: For example, we would look at the size of the head or the shape of the ears.\n",
    "[478.00 - 483.00]: We would use all those to figure out whether an animal were a cat or dog.\n",
    "[483.00 - 487.00]: A neural network does not know what ears are.\n",
    "[487.00 - 492.00]: All it sees is numbers and more numbers and patterns within the numbers.\n",
    "[492.00 - 502.00]: Finally, an output is generated. In this case, a probability that the picture shows a cat and a probability that it is a dog.\n",
    "[502.00 - 509.00]: And that's where training comes in. You need to tell the network whether the result is correct or not.\n",
    "[509.00 - 516.00]: For example, the network puts out 80% probability for dog and 20% for cat.\n",
    "[516.00 - 519.00]: And the image actually shows a dog.\n",
    "[519.00 - 529.00]: Now, the weights of the network that led to the correct dog output will be amplified, while those weights that led to the wrong cat output will be weakened.\n",
    "[529.00 - 536.00]: And once a network has been through millions or even billions of those learning cycles, it will be trained.\n",
    "[536.00 - 542.00]: And it will be pretty good at figuring out whether an image shows a cat or dog.\n",
    "[542.00 - 548.00]: Or recognize handwriting or recognize speech or whatever it was trained to do.\n",
    "[548.00 - 554.00]: And again, the network I've shown is somewhat simplified and even outdated.\n",
    "[554.00 - 561.00]: But it's very good at getting across the basic ideas of machine learning, and that's why I used it.\n",
    "[561.00 - 568.00]: So physics Nobel for machine learning.\n",
    "[568.00 - 577.00]: The justification was that a lot of the basic ideas stem from physical models or physical concepts.\n",
    "[577.00 - 584.00]: And also that the machine learning methods were heavily applied in physics.\n",
    "[584.00 - 592.00]: For example, to analyze output from particle colliders or to construct images of black holes, etc.\n",
    "[592.00 - 600.00]: And all of this is true, but does that mean that artificial neural networks and machine learning is physics?\n",
    "[600.00 - 607.00]: Well, it's not really physics, but it's also not really not physics.\n",
    "[607.00 - 616.00]: And there have been Nobel Prizes in physics before that were closer to mechanical engineering or electrical engineering.\n",
    "[616.00 - 620.00]: And now we also have software engineering.\n",
    "[620.00 - 625.00]: I guess what it all comes down to, at least for me, is that it's physics.\n",
    "[625.00 - 633.00]: I guess what it all comes down to, at least for me, is that it's fine to make this kind of exceptions.\n",
    "[633.00 - 642.00]: But only as an exception, but if this kind of stuff became the norm, why call it Nobel Prizes in physics anymore?\n",
    "[642.00 - 650.00]: I get that. Institutions, especially old institutions, from time to time have to show that they're still up to date and they're still relevant.\n",
    "[650.00 - 655.00]: But you know, you also have to do what you're supposed to do.\n",
    "[655.00 - 659.00]: We don't need a second touring award. We already have one.\n",
    "[659.00 - 668.00]: Anyway, like I said in the intro, this video is focused on the very broad ideas of machine learning.\n",
    "[668.00 - 675.00]: If you're interested in much more detailed treatments, including even math, you can check out those links.\n",
    "[675.00 - 679.00]: I think these are really great videos.\n",
    "[681.00 - 688.00]: As a final thought, hands down the best thing about this was the means.\n",
    "[688.00 - 692.00]: So I'll let you enjoy a couple of those as an outro.\n",
    "[692.00 - 697.00]: See you again next year, hopefully with a little bit more physics.\n",
    "[710.00 - 713.00]: You\n",
    "[740.00 - 743.00]: You\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def analyze_transcript(transcript_path):\n",
    "    \"\"\"Analyze transcript using Ollama LLM.\"\"\"\n",
    "    with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "        transcript_text = f.read()\n",
    "\n",
    "    prompt_template = f\"\"\"\n",
    "    Analyze the following transcript and provide:\n",
    "    1. A concise summary\n",
    "    2. Key points discussed\n",
    "    3. Main topics covered\n",
    "    4. Most important moments with their approximate timestamps (format: [HH:MM:SS] - description)\n",
    "    \n",
    "    Transcript:\n",
    "    {transcript_text}\n",
    "\n",
    "    Respond in the following JSON format:\n",
    "        {{\n",
    "            \"summary\": \"string\",\n",
    "            \"key_points\": [\"point1\", \"point2\", ...],\n",
    "            \"topics\": [\"topic1\", \"topic2\", ...],\n",
    "            \"key_moments\": [\n",
    "                {{\"timestamp\": \"HH:MM:SS\", \"description\": \"string\"}}\n",
    "            ]\n",
    "        }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Respond in the following JSON format:\n",
    "    # {{\n",
    "    #     \"summary\": \"string\",\n",
    "    #     \"key_points\": [\"point1\", \"point2\", ...],\n",
    "    #     \"topics\": [\"topic1\", \"topic2\", ...],\n",
    "    #     \"key_moments\": [\n",
    "    #         {{\"timestamp\": \"HH:MM:SS\", \"description\": \"string\"}}\n",
    "    #     ]\n",
    "    # }}\n",
    "    \n",
    "    # prompt = PromptTemplate(\n",
    "    #     input_variables=[\"transcript\"],\n",
    "    #     template=prompt_template\n",
    "    # )\n",
    "\n",
    "    prompt = prompt_template\n",
    "\n",
    "    # response = ollama.chat(\n",
    "    #     model='llama3.2',\n",
    "    #     messages=[{\n",
    "    #         'role': 'user',\n",
    "    #         'content': prompt,\n",
    "    #         'format': 'json'\n",
    "    #     }]\n",
    "    # )\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        format='json'  # Request JSON format explicitly\n",
    "    )\n",
    "    \n",
    "    # response = model.invoke(prompt.format(transcript=transcript_text))\n",
    "    \n",
    "    try:\n",
    "        # Parse the response to ensure it's valid JSON\n",
    "        analysis_data = json.loads(response['message']['content'])\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback structure if response isn't valid JSON\n",
    "        print('fallback')\n",
    "        analysis_data = {\n",
    "            \"summary\": response['message']['content'],\n",
    "            \"key_points\": [],\n",
    "            \"topics\": [],\n",
    "            \"key_moments\": []\n",
    "        }\n",
    "    \n",
    "    return analysis_data\n",
    "\n",
    "data = analyze_transcript('../transcript.txt')\n",
    "# data = json.loads(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '00:10:00',\n",
       "  'description': 'The speaker introduces the topic of machine learning and its relationship to physics'},\n",
       " {'timestamp': '00:20:00',\n",
       "  'description': \"The Nobel Prize in Physics is awarded to machine learning, sparking debate about whether it's truly a physics prize\"},\n",
       " {'timestamp': '00:30:00',\n",
       "  'description': 'Some argue that machine learning is more closely related to software engineering or electrical engineering than physics'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['key_moments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 207\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohammed\\anaconda3\\envs\\education\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import whisper\n",
    "from ollama import AsyncClient\n",
    "from typing import Dict, Tuple, Any\n",
    "\n",
    "class MediaProcessor:\n",
    "    def __init__(self, base_dir: str = \"media_processing\"):\n",
    "        \"\"\"Initialize the MediaProcessor with necessary directories.\"\"\"\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.temp_dir = self.base_dir / \"temp\"\n",
    "        self.transcription_dir = self.base_dir / \"transcriptions\"\n",
    "        self.keyframes_dir = self.base_dir / \"keyframes\"\n",
    "        \n",
    "        # Create all necessary directories\n",
    "        for dir_path in [self.temp_dir, self.transcription_dir, self.keyframes_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Initialize Whisper model\n",
    "        self.whisper_model = whisper.load_model(\"base\")\n",
    "        \n",
    "        # Initialize Ollama AsyncClient\n",
    "        self.client = AsyncClient()\n",
    "\n",
    "    async def extract_audio(self, mp4_path: str | Path) -> Path:\n",
    "        \"\"\"Extract audio from MP4 and convert to WAV format.\"\"\"\n",
    "        mp4_path = Path(mp4_path)\n",
    "        if not mp4_path.exists():\n",
    "            raise FileNotFoundError(f\"Video file not found: {mp4_path}\")\n",
    "            \n",
    "        wav_path = self.temp_dir / f\"{mp4_path.stem}.wav\"\n",
    "        \n",
    "        command = [\n",
    "            'ffmpeg', '-i', str(mp4_path),\n",
    "            '-vn', '-acodec', 'pcm_s16le',\n",
    "            '-ar', '16000', '-ac', '1',\n",
    "            str(wav_path)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            process = await asyncio.create_subprocess_exec(\n",
    "                *command,\n",
    "                stdout=asyncio.subprocess.PIPE,\n",
    "                stderr=asyncio.subprocess.PIPE\n",
    "            )\n",
    "            stdout, stderr = await process.communicate()\n",
    "            \n",
    "            if process.returncode != 0:\n",
    "                raise RuntimeError(f\"FFmpeg failed: {stderr.decode()}\")\n",
    "                \n",
    "            return wav_path\n",
    "        except Exception as e:\n",
    "            if wav_path.exists():\n",
    "                wav_path.unlink()\n",
    "            raise RuntimeError(f\"Audio extraction failed: {str(e)}\")\n",
    "\n",
    "    async def transcribe_audio(self, wav_path: Path) -> Tuple[Path, Dict[str, Any]]:\n",
    "        \"\"\"Transcribe WAV file using Whisper.\"\"\"\n",
    "        if not wav_path.exists():\n",
    "            raise FileNotFoundError(f\"WAV file not found: {wav_path}\")\n",
    "            \n",
    "        try:\n",
    "            result = await asyncio.to_thread(self.whisper_model.transcribe, str(wav_path))\n",
    "            \n",
    "            transcript_path = self.transcription_dir / f\"{wav_path.stem}_transcript.txt\"\n",
    "            async with asyncio.Lock():\n",
    "                with open(transcript_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(result[\"text\"])\n",
    "            \n",
    "            return transcript_path, result\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Transcription failed: {str(e)}\")\n",
    "\n",
    "    async def analyze_transcript(self, transcript_path: Path) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze transcript using Ollama AsyncClient.\"\"\"\n",
    "        if not transcript_path.exists():\n",
    "            raise FileNotFoundError(f\"Transcript file not found: {transcript_path}\")\n",
    "            \n",
    "        try:\n",
    "            async with asyncio.Lock():\n",
    "                with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "                    transcript_text = f.read()\n",
    "\n",
    "            prompt = f\"\"\"\n",
    "            Analyze the following transcript and provide:\n",
    "            1. A concise summary\n",
    "            2. Key points discussed\n",
    "            3. Main topics covered\n",
    "            4. Most important moments with their approximate timestamps (format: [HH:MM:SS] - description)\n",
    "            \n",
    "            Transcript:\n",
    "            {transcript_text}\n",
    "\n",
    "            Respond in the following JSON format:\n",
    "            {{\n",
    "                \"summary\": \"string\",\n",
    "                \"key_points\": [\"point1\", \"point2\", ...],\n",
    "                \"topics\": [\"topic1\", \"topic2\", ...],\n",
    "                \"key_moments\": [\n",
    "                    {{\"timestamp\": \"HH:MM:SS\", \"description\": \"string\"}}\n",
    "                ]\n",
    "            }}\n",
    "            \"\"\"\n",
    "\n",
    "            response = await self.client.chat(\n",
    "                model='llama2',\n",
    "                messages=[{'role': 'user', 'content': prompt}],\n",
    "                format='json'  # Request JSON format explicitly\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                analysis_data = json.loads(response['message']['content'])\n",
    "            except json.JSONDecodeError:\n",
    "                analysis_data = {\n",
    "                    \"summary\": response['message']['content'],\n",
    "                    \"key_points\": [],\n",
    "                    \"topics\": [],\n",
    "                    \"key_moments\": []\n",
    "                }\n",
    "            \n",
    "            return analysis_data\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Transcript analysis failed: {str(e)}\")\n",
    "\n",
    "    async def extract_keyframes(self, mp4_path: Path, key_moments: list) -> Path:\n",
    "        \"\"\"Extract images from key moments in the MP4 file.\"\"\"\n",
    "        if not mp4_path.exists():\n",
    "            raise FileNotFoundError(f\"Video file not found: {mp4_path}\")\n",
    "            \n",
    "        base_name = mp4_path.stem\n",
    "        keyframes_subdir = self.keyframes_dir / base_name\n",
    "        keyframes_subdir.mkdir(exist_ok=True)\n",
    "        \n",
    "        processes = []\n",
    "        for moment in key_moments:\n",
    "            timestamp = moment.get('timestamp', '00:00:00')\n",
    "            description = moment.get('description', '').replace(' ', '_')[:30]\n",
    "            output_path = keyframes_subdir / f\"keyframe_{timestamp}_{description}.jpg\"\n",
    "            \n",
    "            command = [\n",
    "                'ffmpeg', '-ss', timestamp,\n",
    "                '-i', str(mp4_path),\n",
    "                '-vframes', '1',\n",
    "                '-q:v', '2',\n",
    "                '-y',\n",
    "                str(output_path)\n",
    "            ]\n",
    "            \n",
    "            process = asyncio.create_subprocess_exec(\n",
    "                *command,\n",
    "                stdout=asyncio.subprocess.PIPE,\n",
    "                stderr=asyncio.subprocess.PIPE\n",
    "            )\n",
    "            processes.append(process)\n",
    "        \n",
    "        try:\n",
    "            await asyncio.gather(*(process for process in processes))\n",
    "            return keyframes_subdir\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Keyframe extraction failed: {str(e)}\")\n",
    "\n",
    "    async def process_media(self, mp4_path: str | Path) -> Dict[str, Any]:\n",
    "        \"\"\"Main async processing pipeline.\"\"\"\n",
    "        try:\n",
    "            wav_path = await self.extract_audio(mp4_path)\n",
    "            transcript_path, transcript_result = await self.transcribe_audio(wav_path)\n",
    "            analysis = await self.analyze_transcript(transcript_path)\n",
    "            keyframes_dir = await self.extract_keyframes(mp4_path, analysis.get('key_moments', []))\n",
    "            \n",
    "            # Cleanup\n",
    "            try:\n",
    "                if wav_path.exists():\n",
    "                    wav_path.unlink()\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to cleanup temporary file {wav_path}: {str(e)}\")\n",
    "            \n",
    "            return {\n",
    "                'transcript_path': str(transcript_path),\n",
    "                'analysis': analysis,\n",
    "                'keyframes_dir': str(keyframes_dir)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Cleanup on failure\n",
    "            try:\n",
    "                if 'wav_path' in locals() and wav_path.exists():\n",
    "                    wav_path.unlink()\n",
    "            except Exception:\n",
    "                pass\n",
    "            raise RuntimeError(f\"Media processing failed: {str(e)}\")\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        processor = MediaProcessor()\n",
    "        result = await processor.process_media(\"../ai.mp4\")\n",
    "        print(f\"Transcript saved at: {result['transcript_path']}\")\n",
    "        print(f\"Keyframes saved in: {result['keyframes_dir']}\")\n",
    "        print(f\"Analysis: {result['analysis']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Module': 'Network Troubleshooting Tools', 'Recommended Study Material': {'Filename': 'Intro_to_Networks.pdf', 'Description': 'Basic network principles and models', 'File type': 'PDF', 'Date added': '2024-09-10', 'Key points summary': 'Understanding network protocols, Network device configuration', 'Suggested focus areas': ['Network protocol identification', 'Troubleshooting tools comparison'], 'Study tips': 'Review the basics of network principles and models to understand how different troubleshooting tools work.'}}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "def analyze_transcript():\n",
    "    \"\"\"Analyze transcript using Ollama LLM.\"\"\"\n",
    "\n",
    "    # Cleaned-up prompt formatting\n",
    "    prompt = \"\"\"\n",
    "Generate a comprehensive list of recommended study materials for students preparing for their Computer Networks final exam. Consider the following details:\n",
    "\n",
    "- Exam Type: Final Exam\n",
    "- Syllabus Modules:\n",
    "  - Network Models & Protocols\n",
    "  - Data Link Layer & MAC Addressing\n",
    "  - IP Addressing & Subnetting\n",
    "  - Transport Layer Protocols (TCP/UDP)\n",
    "  - Network Security Basics\n",
    "  - Network Troubleshooting Tools\n",
    "\n",
    "Each recommendation should include:\n",
    "- The filename of the reference.\n",
    "- Description explaining why this material is relevant to the topic.\n",
    "- File type (e.g., PDF, Video, Presentation).\n",
    "- Date added (to prioritize recent materials).\n",
    "- A summary of key points for each module to aid in revision.\n",
    "- Suggested focus areas to help students prioritize topics within each module.\n",
    "- Tips for effectively using each study material to maximize exam preparation.\n",
    "\n",
    "Here is the list of available reference files in the classroom:\n",
    "1. Filename: Intro_to_Networks.pdf | Description: Basic network principles and models | Filetype: PDF | Date added: 2024-09-10\n",
    "2. Filename: Subnetting_Guide.mp4 | Description: Step-by-step guide to IP subnetting | Filetype: Video | Date added: 2024-09-20\n",
    "3. Filename: TCP_vs_UDP.ppt | Description: Comparison of TCP and UDP protocols | Filetype: Presentation | Date added: 2024-10-01\n",
    "4. Filename: Network_Security_101.pdf | Description: Introduction to network security basics | Filetype: PDF | Date added: 2024-10-05\n",
    "5. Filename: Packet_Tracer_Lab.pdf | Description: Hands-on exercises for network troubleshooting using Packet Tracer | Filetype: PDF | Date added: 2024-10-12\n",
    "\n",
    "Output format:\n",
    "1. Module: [Module name, e.g., 'Network Models & Protocols']\n",
    "   - Recommended Study Material:\n",
    "     - Filename: [Filename]\n",
    "     - Description: [Relevance description]\n",
    "     - File type: [File type]\n",
    "     - Date added: [Date]\n",
    "     - Key points summary: [Summary for quick revision]\n",
    "     - Suggested focus areas: [Topics to prioritize for the exam]\n",
    "     - Study tips: [Tips on effectively using this material]\n",
    "\n",
    "Focus on providing materials that align closely with the module topics, are appropriate for the final exam, and offer actionable insights for effective studying.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Call to ollama.generate with simplified JSON parsing\n",
    "    response = ollama.generate(\n",
    "        model='llama3.2',\n",
    "        prompt=prompt,\n",
    "        format='json'\n",
    "    )\n",
    "    \n",
    "    # Ensure the response is a valid JSON string\n",
    "    try:\n",
    "        # Attempt to parse response as JSON\n",
    "        analysis_data = json.loads(response['response'])  # Assuming response is a JSON string\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback structure if response isn't valid JSON\n",
    "        print('JSON decoding failed. Using fallback structure.')\n",
    "        analysis_data = {\n",
    "            \"result\": response,\n",
    "        }\n",
    "\n",
    "    return analysis_data\n",
    "\n",
    "data = analyze_transcript()\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Network Troubleshooting Tools'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Module']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class ExamPrepAssistant:\n",
    "    def __init__(self):\n",
    "        self.model = 'llama3.2'\n",
    "        \n",
    "    def generate_study_guide(self, course_materials: List[Dict], syllabus: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate a comprehensive study guide based on course materials and syllabus.\n",
    "        \n",
    "        Args:\n",
    "            course_materials: List of available study materials with metadata\n",
    "            syllabus: Dictionary containing exam syllabus details\n",
    "        \"\"\"\n",
    "        prompt = self._construct_prompt(course_materials, syllabus)\n",
    "        return self._analyze_with_llm(prompt)\n",
    "    \n",
    "    def _construct_prompt(self, course_materials: List[Dict], syllabus: Dict) -> str:\n",
    "        \"\"\"Construct a detailed prompt for the LLM.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are an experienced computer networks professor creating a comprehensive exam preparation guide.\n",
    "        Your task is to analyze the available course materials and create a structured study plan that will\n",
    "        maximize students' success in their final exam.\n",
    "\n",
    "        EXAM DETAILS:\n",
    "        Course: {syllabus.get('course_name', 'Computer Networks')}\n",
    "        Exam Type: {syllabus.get('exam_type', 'Final Exam')}\n",
    "        Date: {syllabus.get('exam_date', 'Upcoming')}\n",
    "        Duration: {syllabus.get('duration', '3 hours')}\n",
    "        Format: {syllabus.get('format', 'Written + Practical')}\n",
    "\n",
    "        MODULES AND LEARNING OBJECTIVES:\n",
    "        {self._format_modules(syllabus.get('modules', {}))}\n",
    "\n",
    "        AVAILABLE STUDY MATERIALS:\n",
    "        {self._format_materials(course_materials)}\n",
    "\n",
    "        REQUIRED OUTPUT FORMAT:\n",
    "        {{\n",
    "            \"study_guide\": {{\n",
    "                \"modules\": [\n",
    "                    {{\n",
    "                        \"name\": \"Module Name\",\n",
    "                        \"learning_objectives\": [\"obj1\", \"obj2\"],\n",
    "                        \"recommended_materials\": [\n",
    "                            {{\n",
    "                                \"filename\": \"material.pdf\",\n",
    "                                \"relevance_score\": 0-10,\n",
    "                                \"key_concepts\": [\"concept1\", \"concept2\"],\n",
    "                                \"study_approach\": \"Detailed study approach\",\n",
    "                                \"practice_exercises\": [\"exercise1\", \"exercise2\"],\n",
    "                                \"common_pitfalls\": [\"pitfall1\", \"pitfall2\"],\n",
    "                                \"time_allocation\": \"Recommended study time\"\n",
    "                            }}\n",
    "                        ],\n",
    "                        \"revision_strategy\": {{\n",
    "                            \"priority_topics\": [\"topic1\", \"topic2\"],\n",
    "                            \"practice_focus\": \"Areas needing hands-on practice\",\n",
    "                            \"time_management\": \"Time allocation strategy\"\n",
    "                        }},\n",
    "                        \"self_assessment\": [\n",
    "                            {{\n",
    "                                \"question\": \"Practice question\",\n",
    "                                \"concept_tested\": \"Core concept being tested\",\n",
    "                                \"difficulty\": \"Easy/Medium/Hard\"\n",
    "                            }}\n",
    "                        ]\n",
    "                    }}\n",
    "                ],\n",
    "                \"overall_preparation_tips\": [\n",
    "                    {{\n",
    "                        \"category\": \"Time Management\",\n",
    "                        \"recommendations\": [\"tip1\", \"tip2\"]\n",
    "                    }}\n",
    "                ],\n",
    "                \"exam_day_guidelines\": [\n",
    "                    {{\n",
    "                        \"phase\": \"Before/During/After Exam\",\n",
    "                        \"tips\": [\"guideline1\", \"guideline2\"]\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        ADDITIONAL REQUIREMENTS:\n",
    "        1. Prioritize materials based on:\n",
    "        - Alignment with exam objectives\n",
    "        - Recency of content\n",
    "        - Practical application value\n",
    "        - Complexity level appropriate for final exam\n",
    "\n",
    "        2. For each module, include:\n",
    "        - Essential concepts and their interconnections\n",
    "        - Common student misconceptions\n",
    "        - Sample problems with varying difficulty levels\n",
    "        - Practical application scenarios\n",
    "\n",
    "        3. Time management suggestions:\n",
    "        - Module-wise study time allocation\n",
    "        - Practice session recommendations\n",
    "        - Revision schedule framework\n",
    "\n",
    "        4. Focus particularly on:\n",
    "        - Critical thinking development\n",
    "        - Problem-solving strategies\n",
    "        - Practical implementation skills\n",
    "        - Common exam pitfalls to avoid\n",
    "\n",
    "        Please ensure the response is in valid JSON format and provides actionable, specific guidance rather than generic advice.\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def _format_modules(self, modules: Dict) -> str:\n",
    "        \"\"\"Format module information for the prompt.\"\"\"\n",
    "        formatted = []\n",
    "        for module_name, details in modules.items():\n",
    "            objectives = \"\\n      \".join(details.get('objectives', []))\n",
    "            formatted.append(f\"\"\"\n",
    "- {module_name}:\n",
    "    Weight: {details.get('weight', '20%')}\n",
    "    Objectives:\n",
    "      {objectives}\n",
    "\"\"\")\n",
    "        return \"\".join(formatted)\n",
    "    \n",
    "    def _format_materials(self, materials: List[Dict]) -> str:\n",
    "        \"\"\"Format course materials information for the prompt.\"\"\"\n",
    "        formatted = []\n",
    "        for material in materials:\n",
    "            formatted.append(f\"\"\"\n",
    "            - Filename: {material['filename']}\n",
    "                Type: {material['type']}\n",
    "                Description: {material['description']}\n",
    "                Date Added: {material['date_added']}\n",
    "                Topics Covered: {', '.join(material['topics'])}\n",
    "                Difficulty Level: {material['difficulty']}\n",
    "            \"\"\")\n",
    "        return \"\".join(formatted)\n",
    "    \n",
    "    def _analyze_with_llm(self, prompt: str) -> Dict:\n",
    "        \"\"\"Generate study guide using LLM.\"\"\"\n",
    "        try:\n",
    "            response = ollama.generate(\n",
    "                model=self.model,\n",
    "                prompt=prompt,\n",
    "                format='json'\n",
    "            )\n",
    "            return json.loads(response['response'])\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing LLM response: {e}\")\n",
    "            return {\"error\": \"Failed to generate valid study guide\"}\n",
    "        except Exception as e:\n",
    "            print(f\"Error during LLM analysis: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# Example usage\n",
    "def st():\n",
    "    # Sample course materials\n",
    "    materials = [\n",
    "        {\n",
    "            \"filename\": \"Advanced_Networks.pdf\",\n",
    "            \"type\": \"PDF\",\n",
    "            \"description\": \"Comprehensive guide to modern networking\",\n",
    "            \"date_added\": \"2024-10-15\",\n",
    "            \"topics\": [\"OSI Model\", \"TCP/IP\", \"Routing\"],\n",
    "            \"difficulty\": \"Advanced\"\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # Sample syllabus\n",
    "    syllabus = {\n",
    "        \"course_name\": \"Advanced Computer Networks\",\n",
    "        \"exam_type\": \"Final Examination\",\n",
    "        \"exam_date\": \"2024-12-15\",\n",
    "        \"duration\": \"3 hours\",\n",
    "        \"format\": \"Written + Lab\",\n",
    "        \"modules\": {\n",
    "            \"Network Architecture\": {\n",
    "                \"weight\": \"25%\",\n",
    "                \"objectives\": [\n",
    "                    \"Understand OSI and TCP/IP models\",\n",
    "                    \"Compare different network topologies\",\n",
    "                    \"Analyze protocol layering and encapsulation\"\n",
    "                ]\n",
    "            },\n",
    "            # Add more modules...\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    assistant = ExamPrepAssistant()\n",
    "    study_guide = assistant.generate_study_guide(materials, syllabus)\n",
    "    \n",
    "    # Pretty print the study guide\n",
    "    print(json.dumps(study_guide, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"study_guide\": {\n",
      "    \"modules\": [\n",
      "      {\n",
      "        \"name\": \"Network Architecture\",\n",
      "        \"learning_objectives\": [\n",
      "          \"Understand OSI and TCP/IP models\",\n",
      "          \"Compare different network topologies\",\n",
      "          \"Analyze protocol layering and encapsulation\"\n",
      "        ],\n",
      "        \"recommended_materials\": [\n",
      "          {\n",
      "            \"filename\": \"Advanced_Networks.pdf\",\n",
      "            \"relevance_score\": 9,\n",
      "            \"key_concepts\": [\n",
      "              \"OSI Model\",\n",
      "              \"TCP/IP model\",\n",
      "              \"Network Topology\"\n",
      "            ],\n",
      "            \"study_approach\": \"Detailed study approach\",\n",
      "            \"practice_exercises\": [\n",
      "              \"Exercise 1.1: OSI Model Comparison\",\n",
      "              \"Exercise 2.2: TCP/IP Model Analysis\"\n",
      "            ],\n",
      "            \"common_pitfalls\": [\n",
      "              \"Misunderstanding the difference between the OSI and TCP/IP models\",\n",
      "              \"Failing to recognize the importance of protocol layering\"\n",
      "            ],\n",
      "            \"time_allocation\": \"2 hours/1 hour for practice exercises\"\n",
      "          },\n",
      "          {\n",
      "            \"filename\": \"Network Topology.pdf\",\n",
      "            \"relevance_score\": 8,\n",
      "            \"key_concepts\": [\n",
      "              \"Bus Topology\",\n",
      "              \"Star Topology\",\n",
      "              \"Ring Topology\"\n",
      "            ],\n",
      "            \"study_approach\": \"Detailed study approach\",\n",
      "            \"practice_exercises\": [\n",
      "              \"Exercise 3.1: Bus Topology Analysis\",\n",
      "              \"Exercise 4.2: Star Topology Design\"\n",
      "            ],\n",
      "            \"common_pitfalls\": [\n",
      "              \"Failing to recognize the limitations of bus topology\",\n",
      "              \"Misapplying star topology in a ring network\"\n",
      "            ],\n",
      "            \"time_allocation\": \"1 hour/1 hour for practice exercises\"\n",
      "          }\n",
      "        ],\n",
      "        \"revision_strategy\": {\n",
      "          \"priority_topics\": [\n",
      "            \"OSI Model\",\n",
      "            \"TCP/IP model\"\n",
      "          ],\n",
      "          \"practice_focus\": \"Exercise 2.2: TCP/IP Model Analysis and Exercise 3.1: Bus Topology Analysis\",\n",
      "          \"time_management\": \" Allocate 30 minutes for each priority topic\"\n",
      "        },\n",
      "        \"self_assessment\": [\n",
      "          {\n",
      "            \"question\": \"What is the primary difference between the OSI and TCP/IP models?\",\n",
      "            \"concept_tested\": \"OSI Model vs TCP/IP model\",\n",
      "            \"difficulty\": \"Medium\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"name\": \"Routing\",\n",
      "        \"learning_objectives\": [\n",
      "          \"Understand routing protocols (RIP, OSPF, EIGRP)\",\n",
      "          \"Analyze routing table management and optimization\"\n",
      "        ],\n",
      "        \"recommended_materials\": [\n",
      "          {\n",
      "            \"filename\": \"Routing Protocols.pdf\",\n",
      "            \"relevance_score\": 9,\n",
      "            \"key_concepts\": [\n",
      "              \"RIP\",\n",
      "              \"OSPF\",\n",
      "              \"EIGRP\"\n",
      "            ],\n",
      "            \"study_approach\": \"Detailed study approach\",\n",
      "            \"practice_exercises\": [\n",
      "              \"Exercise 5.1: RIP Analysis\",\n",
      "              \"Exercise 6.2: OSPF Design\"\n",
      "            ],\n",
      "            \"common_pitfalls\": [\n",
      "              \"Failing to recognize the limitations of RIP\",\n",
      "              \"Misapplying OSPF in a simple network\"\n",
      "            ],\n",
      "            \"time_allocation\": \"2 hours/1 hour for practice exercises\"\n",
      "          },\n",
      "          {\n",
      "            \"filename\": \"Routing Table Management.pdf\",\n",
      "            \"relevance_score\": 8,\n",
      "            \"key_concepts\": [\n",
      "              \"Routing table optimization\",\n",
      "              \"Route summarization\"\n",
      "            ],\n",
      "            \"study_approach\": \"Detailed study approach\",\n",
      "            \"practice_exercises\": [\n",
      "              \"Exercise 7.1: Routing Table Analysis\",\n",
      "              \"Exercise 8.2: Route Summarization Design\"\n",
      "            ],\n",
      "            \"common_pitfalls\": [\n",
      "              \"Failing to optimize routing tables\",\n",
      "              \"Misapplying route summarization\"\n",
      "            ],\n",
      "            \"time_allocation\": \"1 hour/1 hour for practice exercises\"\n",
      "          }\n",
      "        ],\n",
      "        \"revision_strategy\": {\n",
      "          \"priority_topics\": [\n",
      "            \"RIP\",\n",
      "            \"OSPF\"\n",
      "          ],\n",
      "          \"practice_focus\": \"Exercise 5.1: RIP Analysis and Exercise 6.2: OSPF Design\",\n",
      "          \"time_management\": \"Allocate 30 minutes for each priority topic\"\n",
      "        },\n",
      "        \"self_assessment\": [\n",
      "          {\n",
      "            \"question\": \"What is the primary difference between RIP and OSPF?\",\n",
      "            \"concept_tested\": \"RIP vs OSPF\",\n",
      "            \"difficulty\": \"Medium\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"overall_preparation_tips\": [\n",
      "      {\n",
      "        \"category\": \"Time Management\",\n",
      "        \"recommendations\": [\n",
      "          \"Allocate at least 2 hours for studying each module\",\n",
      "          \"Practice exercises should account for 30% of total study time\",\n",
      "          \"Revision schedule framework: allocate more time to priority topics\"\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"exam_day_guidelines\": [\n",
      "      {\n",
      "        \"phase\": \"Before/During/After Exam\",\n",
      "        \"tips\": [\n",
      "          \"Bring multiple copies of your identification and exam materials\",\n",
      "          \"Read the exam instructions carefully before starting the test\",\n",
      "          \"Use the allotted time wisely, and avoid spending too much time on a single question\"\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "st()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "education",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
